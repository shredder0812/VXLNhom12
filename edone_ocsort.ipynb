{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shredder0812/VXLNhom12/blob/test/edone_ocsort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf6uzZMcPkKN",
        "outputId": "337b0d1b-6568-43c9-e269-9740121b2a24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Daday_3.mp4 /content/drive/MyDrive/best.pt /content"
      ],
      "metadata": {
        "id": "GD98yE2QlHyB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "id": "CGKDXyOkPBGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!git clone https://github.com/KeeganFernandesWork/yolo_tracking\n",
        "%cd yolo_tracking\n",
        "!pip install -r requirements.txt\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "sMh0ZfK7MRV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from boxmot import (OCSORT, BoTSORT, BYTETracker, DeepOCSORT, StrongSORT,\n",
        "                    create_tracker, get_tracker_config)\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import datetime\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "fnL9wU6UMUVY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video Writer"
      ],
      "metadata": {
        "id": "lJuMCyVqMWXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sys.path.insert(1, '/kaggle/input/video-weights')\n",
        "\n",
        "def create_video_writer(video_cap, output_filename):\n",
        "\n",
        "    # grab the width, height, and fps of the frames in the video stream.\n",
        "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # initialize the FourCC and a video writer object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n",
        "                             (frame_width, frame_height))\n",
        "\n",
        "    return writer"
      ],
      "metadata": {
        "id": "1om_L1o9MW8O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color = (0, 0, 255)  # BGR\n",
        "thickness = 2\n",
        "fontscale = 0.5\n",
        "\n",
        "device = \"cuda:0\" # cuda:0 , cpu\n",
        "fp16 = True # True if gpu available\n",
        "# load the pre-trained YOLOv8n model\n",
        "model = YOLO(\"/content/best.pt\")\n",
        "source = \"/content/Daday_3.mp4\""
      ],
      "metadata": {
        "id": "Ij-Bex6OMZPK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing DeepOCSORT"
      ],
      "metadata": {
        "id": "ArmeJfDiMcOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(DeepOCSORT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrIGz9bhQ-mk",
        "outputId": "afd19824-e8bc-41ab-d819-01792ab33fdc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class DeepOCSort in module boxmot.trackers.deepocsort.deep_ocsort:\n",
            "\n",
            "class DeepOCSort(builtins.object)\n",
            " |  DeepOCSort(model_weights, device, fp16, per_class=True, det_thresh=0.3, max_age=30, min_hits=3, iou_threshold=0.3, delta_t=3, asso_func='iou', inertia=0.2, w_association_emb=0.75, alpha_fixed_emb=0.95, aw_param=0.5, embedding_off=False, cmc_off=False, aw_off=False, new_kf_off=False, **kwargs)\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, model_weights, device, fp16, per_class=True, det_thresh=0.3, max_age=30, min_hits=3, iou_threshold=0.3, delta_t=3, asso_func='iou', inertia=0.2, w_association_emb=0.75, alpha_fixed_emb=0.95, aw_param=0.5, embedding_off=False, cmc_off=False, aw_off=False, new_kf_off=False, **kwargs)\n",
            " |      Sets key parameters for SORT\n",
            " |  \n",
            " |  dump_cache(self)\n",
            " |  \n",
            " |  update = wrapper(*args, **kwargs)\n",
            " |  \n",
            " |  update_public(self, dets, cates, scores)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tracker = DeepOCSORT(\n",
        "    model_weights=Path('osnet_x0_25_msmt17.pt'), # which ReID model to use\n",
        "    device=device,\n",
        "    fp16=fp16,\n",
        ")\n",
        "vid = cv2.VideoCapture(source)\n",
        "writer = create_video_writer(vid, \"DeepOCSORT.mp4\")\n",
        "\n",
        "while True:\n",
        "    ret, im = vid.read()\n",
        "\n",
        "    detections = model.predict(im )[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # initialize the list of bounding boxes and confidences\n",
        "    results = []\n",
        "    if not ret:\n",
        "        break\n",
        "    print(np.array(detections.boxes.data.tolist()).ndim) # 2 -> polyp, 1 -> no detect\n",
        "    #print(results)\n",
        "\n",
        "\n",
        "\n",
        "    if np.array(detections.boxes.data.tolist()).ndim < 2:\n",
        "        results = [[0, 0, 0, 0, 0.0922948837280273],[ 0]]\n",
        "\n",
        "    ts = tracker.update(np.array(detections.boxes.data.tolist()), im) # --> (x, y, x, y, id, conf, cls)\n",
        "\n",
        "    xyxys = ts[:,0:4].astype('int') # float64 to int\n",
        "    ids = ts[:, 4].astype('int') # float64 to int\n",
        "    confs = ts[:, 5]\n",
        "    clss = ts[:, 6]\n",
        "\n",
        "    # print bboxes with their associated id, cls and conf\n",
        "    if ts.shape[0] != 0:\n",
        "        for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n",
        "            im = cv2.rectangle(\n",
        "                im,\n",
        "                (xyxy[0], xyxy[1]),\n",
        "                (xyxy[2], xyxy[3]),\n",
        "                color,\n",
        "                thickness\n",
        "            )\n",
        "            cv2.putText(\n",
        "                im,\n",
        "                f'id: {id}, conf: {conf}, c: {cls}',\n",
        "                (xyxy[0], xyxy[1]-10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                fontscale,\n",
        "                color,\n",
        "                thickness\n",
        "            )\n",
        "\n",
        "    # show the frame to our screen\n",
        "\n",
        "    writer.write(im)\n",
        "\n",
        "\n",
        "vid.release()\n",
        "writer.release()\n",
        "print(\"Task Completed\")"
      ],
      "metadata": {
        "id": "xG_UBMSyMaPL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "5ce47747-f01f-46fe-f4db-7cc2c5068270"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-02-22 15:22:04.061\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m187\u001b[0m - \u001b[32m\u001b[1mSuccessfully loaded pretrained weights from \"osnet_x0_25_msmt17.pt\"\u001b[0m\n",
            "\u001b[32m2024-02-22 15:22:04.063\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m191\u001b[0m - \u001b[33m\u001b[1mThe following layers are discarded due to unmatched keys or layer size: ('classifier.weight', 'classifier.bias')\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 512x640 1 polyp, 73.7ms\n",
            "Speed: 3.2ms preprocess, 73.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "2\n",
            "\n",
            "0: 512x640 1 polyp, 72.6ms\n",
            "Speed: 2.5ms preprocess, 72.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "2\n",
            "\n",
            "0: 512x640 1 polyp, 72.4ms\n",
            "Speed: 2.3ms preprocess, 72.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "2\n",
            "\n",
            "0: 512x640 1 polyp, 71.0ms\n",
            "Speed: 2.5ms preprocess, 71.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "2\n",
            "\n",
            "0: 512x640 1 polyp, 69.4ms\n",
            "Speed: 2.2ms preprocess, 69.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "2\n",
            "\n",
            "0: 512x640 1 polyp, 64.0ms\n",
            "Speed: 2.2ms preprocess, 64.0ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "2\n",
            "\n",
            "0: 512x640 (no detections), 59.8ms\n",
            "Speed: 2.6ms preprocess, 59.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Unsupported 'dets' dimensions, valid number of dimensions is two",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8373ba70d766>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0922948837280273\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# --> (x, y, x, y, id, conf, cls)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mxyxys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# float64 to int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/yolo_tracking/boxmot/utils/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[0mmc_dets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmc_dets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mmc_dets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Per class updates output: {mc_dets.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmc_dets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/yolo_tracking/boxmot/trackers/deepocsort/deep_ocsort.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dets, img, tag)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Unsupported 'dets' input type '{type(dets)}', valid format is np.ndarray\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Unsupported 'img' input type '{type(img)}', valid format is np.ndarray\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unsupported 'dets' dimensions, valid number of dimensions is two\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unsupported 'dets' 2nd dimension lenght, valid lenghts is 6\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Unsupported 'dets' dimensions, valid number of dimensions is two"
          ]
        }
      ]
    }
  ]
}